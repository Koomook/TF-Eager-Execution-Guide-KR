{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# Eager Execution 튜토리얼: 기초\n",
    "\n",
    "본 노트북은 텐서플로우의 eager execution의 기능을 소개하기 위한 기초 자료입니다. 다음과 같은 내용을 포함하고 있습니다:\n",
    "* 필요한 패키지 불러오기\n",
    "* eager execution 활성화\n",
    "* TensorFlow 텐서와 변수를 만들고 사용하기 \n",
    "* TensorFlow와 상호작용하며 사용하기\n",
    "* eager execution 활성화 상태에서 GPU 사용하기 \n",
    "\n",
    "본 노트북은 그레디언트와 같은 모델링 토픽은 다루고 있지 않습니다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Step 1: Eager 불러오기\n",
    "eager execution을 위해서 다음과 같이 import 하세요:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TensorFlow 불러오기\n",
    "import tensorflow as tf\n",
    "\n",
    "# tfe 모듈은 즉시 실행 모드와 그래프 실행 모드 양쪽다 동작하는 다양한 기능들을 포함하고 있습니다.\n",
    "import tensorflow.contrib.eager as tfe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.enable_eager_execution()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor(3, shape=(), dtype=int32)\n",
      "tf.Tensor([4 6], shape=(2,), dtype=int32)\n",
      "tf.Tensor(25, shape=(), dtype=int32)\n",
      "tf.Tensor(6, shape=(), dtype=int32)\n",
      "tf.Tensor(aGVsbG8gd29ybGQ, shape=(), dtype=string)\n",
      "\n",
      "tf.Tensor(7, shape=(), dtype=int32)\n",
      "tf.Tensor(\n",
      "[0.08000001 0.31000003 0.77000004 1.         0.77       0.30999985\n",
      " 0.08000001], shape=(7,), dtype=float32)\n"
     ]
    }
   ],
   "source": [
    "print(tf.add(1, 2))\n",
    "print(tf.add([1, 2], [3, 4]))\n",
    "print(tf.square(5))\n",
    "print(tf.reduce_sum([1, 2, 3]))\n",
    "print(tf.encode_base64(\"hello world\"))\n",
    "print(\"\")\n",
    "\n",
    "x = tf.constant(2)\n",
    "y = tf.constant(3)\n",
    "print(x * y + 1)\n",
    "\n",
    "# 대부분의 TensorFlow 연산은 eager execution에서 즉시 사용가능합니다.\n",
    "# 다음과 같이 즉시 값을 반환해줍니다.\n",
    "print(tf.contrib.signal.hamming_window(x * y + 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "numpy 3x3 matrix of 1s:\n",
      "[[1. 1. 1.]\n",
      " [1. 1. 1.]\n",
      " [1. 1. 1.]]\n",
      "\n",
      "Multiplied by 42:\n",
      "tf.Tensor(\n",
      "[[42. 42. 42.]\n",
      " [42. 42. 42.]\n",
      " [42. 42. 42.]], shape=(3, 3), dtype=float64)\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "ones = np.ones([3, 3])\n",
    "\n",
    "print(\"1로 구성된 numpy 3x3행렬은:\")\n",
    "print(ones)\n",
    "print(\"\")\n",
    "\n",
    "print(\"42를 곱하면:\")\n",
    "print(tf.multiply(ones, 42))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = tf.get_variable(name=\"x\", shape=[], dtype=tf.float32, initializer=tf.zeros_initializer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Printing a TensorFlow Variable:\n",
      "<tf.Variable 'x:0' shape=() dtype=float32, numpy=0.0>\n",
      "\n",
      "Printing a TensorFlow Variable's value using .read_value():\n",
      "tf.Tensor(0.0, shape=(), dtype=float32)\n",
      "\n",
      "Printing a TensorFlow Variable's value using .read_value().numpy():\n",
      "0.0\n"
     ]
    }
   ],
   "source": [
    "# This does NOT print the Variable's actual value:\n",
    "print(\"Printing a TensorFlow Variable:\")\n",
    "print(x)\n",
    "print(\"\")\n",
    "\n",
    "# A TensorFlow variable represents a reference to a tensor.\n",
    "# The `read_value()` method provides access to the current value of the\n",
    "# variable. Tensorflow Variables are automatically initialized according to the\n",
    "# semantics defined in tf.get_variable().\n",
    "print(\"Printing a TensorFlow Variable's value using .read_value():\")\n",
    "print(x.read_value())\n",
    "print(\"\")\n",
    "\n",
    "print(\"Printing a TensorFlow Variable's value using .read_value().numpy():\")\n",
    "print(x.read_value().numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor(42.0, shape=(), dtype=float32)\n",
      "tf.Tensor(45.0, shape=(), dtype=float32)\n"
     ]
    }
   ],
   "source": [
    "x.assign(42)\n",
    "print(x.read_value())\n",
    "\n",
    "x.assign_add(3)\n",
    "print(x.read_value())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor(48.0, shape=(), dtype=float32)\n",
      "tf.Tensor([ 45.  90. 180.], shape=(3,), dtype=float32)\n"
     ]
    }
   ],
   "source": [
    "print(x + 3)\n",
    "\n",
    "# This code will broadcast the value across the list of numbers:\n",
    "print(x * [1, 2, 4])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "vector = tf.constant([10.0, 20.0, 30.0, 40.0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor([20. 30. 40.], shape=(3,), dtype=float32)\n"
     ]
    }
   ],
   "source": [
    "# Works, because the values of `begin` and `size` (the 2nd and 3rd input\n",
    "# arguments) are within the bound of `vector`.\n",
    "print(tf.slice(vector, [1], [3]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Caught error: Expected size[0] in [0, 3], but got 4 [Op:Slice]\n"
     ]
    }
   ],
   "source": [
    "# The following does NOT work, because the value of `size` (the 3rd\n",
    "# argument) causes the indices to go out of the bounds of `vector`. The\n",
    "# error is raised immediately.\n",
    "try:\n",
    "  print(tf.slice(vector, [1], [4]))\n",
    "except tf.OpError as e:\n",
    "  print(\"Caught error: %s\" % e)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The example code from here on will work only if your notebook\n",
    "# is running on a machine with a functional CUDA GPU. The following\n",
    "# line checks that.\n",
    "is_gpu_available = tfe.num_gpus() > 0\n",
    "\n",
    "# Create some Tensors\n",
    "SIZE = 1000\n",
    "cpu_tensor = tf.random_normal([SIZE, SIZE])\n",
    "\n",
    "if is_gpu_available:\n",
    "  gpu_tensor = cpu_tensor.gpu()\n",
    "else:\n",
    "  print(\"GPU not available.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time to conduct matmul on CPU:\n",
      "CPU times: user 196 ms, sys: 0 ns, total: 196 ms\n",
      "Wall time: 64.9 ms\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: id=104, shape=(1000, 1000), dtype=float32, numpy=\n",
       "array([[ 22.38106  ,   5.633296 ,  13.299532 , ...,  31.061148 ,\n",
       "         -7.768629 , -48.17466  ],\n",
       "       [ 43.470367 ,   1.5255723, -32.61236  , ..., -23.339508 ,\n",
       "        -32.330822 , -33.298195 ],\n",
       "       [  6.201656 ,  45.583122 ,  29.281898 , ..., -72.03731  ,\n",
       "         15.40768  ,  25.029882 ],\n",
       "       ...,\n",
       "       [ 25.847857 ,  38.240105 , -41.389606 , ..., -18.695236 ,\n",
       "        -26.908352 ,  49.71857  ],\n",
       "       [-10.576298 , -13.079933 ,  -6.115379 , ..., -37.376156 ,\n",
       "        -40.50897  , -16.68614  ],\n",
       "       [ 18.368586 , -42.574005 , -20.013565 , ...,  15.061981 ,\n",
       "         -5.717218 , -28.637989 ]], dtype=float32)>"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Time a CPU-based matrix multiplication\n",
    "\n",
    "print(\"Time to conduct matmul on CPU:\")\n",
    "%time tf.matmul(cpu_tensor, cpu_tensor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time to conduct first matmul on GPU:\n",
      "CPU times: user 92 ms, sys: 60 ms, total: 152 ms\n",
      "Wall time: 667 ms\n",
      "()\n",
      "Time to conduct second matmul on GPU:\n",
      "CPU times: user 0 ns, sys: 0 ns, total: 0 ns\n",
      "Wall time: 143 µs\n"
     ]
    }
   ],
   "source": [
    "# Time GPU-based matrix multiplications.\n",
    "\n",
    "if is_gpu_available:\n",
    "  # First use of the GPU will be slow:\n",
    "  print(\"Time to conduct first matmul on GPU:\")\n",
    "  %time tf.matmul(gpu_tensor, gpu_tensor)\n",
    "  print()\n",
    "\n",
    "  # Subsequent uses are much faster:\n",
    "  print(\"Time to conduct second matmul on GPU:\")\n",
    "  %time tf.matmul(gpu_tensor, gpu_tensor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time to conduct CPU matmul:\n",
      "CPU times: user 192 ms, sys: 0 ns, total: 192 ms\n",
      "Wall time: 48.5 ms\n",
      "()\n",
      "Time to conduct GPU matmul:\n",
      "CPU times: user 0 ns, sys: 0 ns, total: 0 ns\n",
      "Wall time: 173 µs\n"
     ]
    }
   ],
   "source": [
    "# Second timing demo for GPUs, after it has been used once:\n",
    "\n",
    "cpu_tensor = tf.random_normal([SIZE, SIZE])\n",
    "print(\"Time to conduct CPU matmul:\")\n",
    "%time tf.matmul(cpu_tensor, cpu_tensor)\n",
    "print()\n",
    "\n",
    "if is_gpu_available:\n",
    "  gpu_tensor = cpu_tensor.gpu()\n",
    "  print(\"Time to conduct GPU matmul:\")\n",
    "  %time tf.matmul(gpu_tensor, gpu_tensor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
