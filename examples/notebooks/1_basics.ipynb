{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# Eager Execution 튜토리얼: 기초\n",
    "\n",
    "본 노트북은 텐서플로우의 eager execution의 기능을 소개하기 위한 기초 자료입니다. 다음과 같은 내용을 포함하고 있습니다:\n",
    "* 필요한 패키지 불러오기\n",
    "* eager execution 활성화\n",
    "* TensorFlow 텐서와 변수를 만들고 사용하기 \n",
    "* TensorFlow와 상호작용하며 사용하기\n",
    "* eager execution 활성화 상태에서 GPU 사용하기 \n",
    "\n",
    "본 노트북은 그레디언트와 같은 모델링 토픽은 다루고 있지 않습니다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Step 1: Eager 불러오기\n",
    "eager execution을 위해서 다음과 같이 import 하세요:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /usr/local/lib/python3.5/dist-packages/tensorflow/contrib/learn/python/learn/datasets/base.py:198: retry (from tensorflow.contrib.learn.python.learn.datasets.base) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use the retry module or similar alternatives.\n",
      "TensorFlow version: 1.7.0\n",
      "Eager execution: True\n"
     ]
    }
   ],
   "source": [
    "from __future__ import absolute_import, division, print_function\n",
    "\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import tensorflow as tf\n",
    "import tensorflow.contrib.eager as tfe\n",
    "\n",
    "tf.enable_eager_execution()\n",
    "\n",
    "print(\"TensorFlow version: {}\".format(tf.VERSION))\n",
    "print(\"Eager execution: {}\".format(tf.executing_eagerly()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor(3, shape=(), dtype=int32)\n",
      "tf.Tensor([4 6], shape=(2,), dtype=int32)\n",
      "tf.Tensor(25, shape=(), dtype=int32)\n",
      "tf.Tensor(6, shape=(), dtype=int32)\n",
      "tf.Tensor(b'aGVsbG8gd29ybGQ', shape=(), dtype=string)\n",
      "\n",
      "tf.Tensor(7, shape=(), dtype=int32)\n",
      "tf.Tensor(\n",
      "[0.08000001 0.31000003 0.77000004 1.         0.77       0.30999985\n",
      " 0.08000001], shape=(7,), dtype=float32)\n"
     ]
    }
   ],
   "source": [
    "print(tf.add(1, 2))\n",
    "print(tf.add([1, 2], [3, 4]))\n",
    "print(tf.square(5))\n",
    "print(tf.reduce_sum([1, 2, 3]))\n",
    "print(tf.encode_base64(\"hello world\"))\n",
    "print(\"\")\n",
    "\n",
    "x = tf.constant(2)\n",
    "y = tf.constant(3)\n",
    "print(x * y + 1)\n",
    "\n",
    "# 대부분의 TensorFlow 연산은 eager execution에서 즉시 사용가능합니다.\n",
    "# 다음과 같이 즉시 값을 반환해줍니다.\n",
    "print(tf.contrib.signal.hamming_window(x * y + 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1로 구성된 numpy 3x3행렬은:\n",
      "[[1. 1. 1.]\n",
      " [1. 1. 1.]\n",
      " [1. 1. 1.]]\n",
      "\n",
      "42를 곱하면:\n",
      "tf.Tensor(\n",
      "[[42. 42. 42.]\n",
      " [42. 42. 42.]\n",
      " [42. 42. 42.]], shape=(3, 3), dtype=float64)\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "ones = np.ones([3, 3])\n",
    "\n",
    "print(\"1로 구성된 numpy 3x3행렬은:\")\n",
    "print(ones)\n",
    "print(\"\")\n",
    "\n",
    "print(\"42를 곱하면:\")\n",
    "print(tf.multiply(ones, 42))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = tf.get_variable(name=\"x\", shape=[], dtype=tf.float32, initializer=tf.zeros_initializer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Printing a TensorFlow Variable:\n",
      "<tf.Variable 'x:0' shape=() dtype=float32, numpy=0.0>\n",
      "\n",
      "Printing a TensorFlow Variable's value using .read_value():\n",
      "tf.Tensor(0.0, shape=(), dtype=float32)\n",
      "\n",
      "Printing a TensorFlow Variable's value using .read_value().numpy():\n",
      "0.0\n"
     ]
    }
   ],
   "source": [
    "# 이 구문은 변수의 실제 값을 출력하지 않습니다:\n",
    "print(\"Printing a TensorFlow Variable:\")\n",
    "print(x)\n",
    "print(\"\")\n",
    "\n",
    "# TensorFlow 변수는 텐서에 대한 참조를 나타냅니다.\n",
    "# `read_value()` 함수는 변수의 현재 값에 접근할 수 있도록 합니다. \n",
    "# Tensorflow 변수는 tf.get_variable()에 정의된대로 자동적으로 초기화 됩니다.\n",
    "print(\"Printing a TensorFlow Variable's value using .read_value():\")\n",
    "print(x.read_value())\n",
    "print(\"\")\n",
    "\n",
    "print(\"Printing a TensorFlow Variable's value using .read_value().numpy():\")\n",
    "print(x.read_value().numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor(42.0, shape=(), dtype=float32)\n",
      "tf.Tensor(45.0, shape=(), dtype=float32)\n"
     ]
    }
   ],
   "source": [
    "x.assign(42)\n",
    "print(x.read_value())\n",
    "\n",
    "x.assign_add(3)\n",
    "print(x.read_value())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor(48.0, shape=(), dtype=float32)\n",
      "tf.Tensor([ 45.  90. 180.], shape=(3,), dtype=float32)\n"
     ]
    }
   ],
   "source": [
    "print(x + 3)\n",
    "\n",
    "# 이 코드는 숫자의 리스트에 대해 자동으로 브로드캐스팅 됩니다.\n",
    "print(x * [1, 2, 4])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "vector = tf.constant([10.0, 20.0, 30.0, 40.0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor([20. 30. 40.], shape=(3,), dtype=float32)\n"
     ]
    }
   ],
   "source": [
    "# 2번째, 3번째 인자로 전달된 `begin`과 `size`가 `vector`의 범위 내에 포함되어서 잘 동작합니다.\n",
    "print(tf.slice(vector, [1], [3]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Caught error: Expected size[0] in [0, 3], but got 4 [Op:Slice]\n"
     ]
    }
   ],
   "source": [
    "# 이 코드는 동작하지 않습니다.\n",
    "# 3번째 인자인 `size`가 `vector`의 범위를 넘어서는 인덱스를 요청했기 때문입니다.\n",
    "# 에러는 즉시 발생합니다.\n",
    "try:\n",
    "  print(tf.slice(vector, [1], [4]))\n",
    "except tf.OpError as e:\n",
    "  print(\"Caught error: %s\" % e)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 본 예제 코드는 사용자의 노트북이 CUDA GPU 환경에서 동작 할 경우에만 작동합니다.\n",
    "# 아래 구문이 해당 사항을 체크합니다.\n",
    "is_gpu_available = tfe.num_gpus() > 0\n",
    "\n",
    "# 임의의 Tensors를 만듭니다. \n",
    "SIZE = 1000\n",
    "cpu_tensor = tf.random_normal([SIZE, SIZE])\n",
    "\n",
    "if is_gpu_available:\n",
    "  gpu_tensor = cpu_tensor.gpu()\n",
    "else:\n",
    "  print(\"GPU not available.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU에서 matmul에 걸리는 시간:\n",
      "CPU times: user 108 ms, sys: 0 ns, total: 108 ms\n",
      "Wall time: 43 ms\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: id=96, shape=(1000, 1000), dtype=float32, numpy=\n",
       "array([[   7.084673 ,   56.023304 , -109.85308  , ...,    0.858407 ,\n",
       "         -33.955086 ,   14.23424  ],\n",
       "       [  -5.7779913,   13.537379 ,  -65.76546  , ...,  -13.514355 ,\n",
       "         -21.036415 ,  -23.941998 ],\n",
       "       [ -24.80651  ,   11.101314 ,   29.67744  , ...,   29.810043 ,\n",
       "          49.076576 ,   16.461351 ],\n",
       "       ...,\n",
       "       [ -22.55507  ,   11.751124 ,   26.205606 , ...,  -10.737196 ,\n",
       "         -25.52725  ,   39.644978 ],\n",
       "       [ -13.076582 ,  -14.075956 ,  -14.266737 , ...,    3.357493 ,\n",
       "         -27.851429 ,  -26.955614 ],\n",
       "       [   9.08893  ,   24.286556 ,   12.602869 , ...,   -5.659523 ,\n",
       "         -51.025173 ,  -12.490817 ]], dtype=float32)>"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# CPU 기반 행렬 곱셈 시간 측정\n",
    "\n",
    "print(\"CPU에서 matmul에 걸리는 시간:\")\n",
    "%time tf.matmul(cpu_tensor, cpu_tensor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GPU에서 첫번째 matmul에 걸리는 시간:\n",
      "CPU times: user 112 ms, sys: 64 ms, total: 176 ms\n",
      "Wall time: 604 ms\n",
      "\n",
      "GPU에서 두번째 matmul에 걸리는 시간:\n",
      "CPU times: user 0 ns, sys: 0 ns, total: 0 ns\n",
      "Wall time: 527 µs\n"
     ]
    }
   ],
   "source": [
    "# GPU 기반 행렬 곱셈 시간 측정\n",
    "\n",
    "if is_gpu_available:\n",
    "  # 처음엔 GPU 초기화 때문에 시간이 걸립니다. :\n",
    "  print(\"GPU에서 첫번째 matmul에 걸리는 시간:\")\n",
    "  %time tf.matmul(gpu_tensor, gpu_tensor)\n",
    "  print()\n",
    "\n",
    "  # 연속적으로 사용할 경우 훨씬 빠릅니다.:\n",
    "  print(\"GPU에서 두번째 matmul에 걸리는 시간:\")\n",
    "  %time tf.matmul(gpu_tensor, gpu_tensor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU에서 matmul에 걸리는 시간:\n",
      "CPU times: user 104 ms, sys: 0 ns, total: 104 ms\n",
      "Wall time: 26.7 ms\n",
      "\n",
      "GPU에서 matmul에 걸리는 시간:\n",
      "CPU times: user 0 ns, sys: 0 ns, total: 0 ns\n",
      "Wall time: 580 µs\n"
     ]
    }
   ],
   "source": [
    "# 두번째 시간을 GPU를 위한 데모로 측정, 첫번째는 초기화 과정으로 통과 시킵니다:\n",
    "\n",
    "cpu_tensor = tf.random_normal([SIZE, SIZE])\n",
    "print(\"CPU에서 matmul에 걸리는 시간:\")\n",
    "%time tf.matmul(cpu_tensor, cpu_tensor)\n",
    "print()\n",
    "\n",
    "if is_gpu_available:\n",
    "  gpu_tensor = cpu_tensor.gpu()\n",
    "  print(\"GPU에서 matmul에 걸리는 시간:\")\n",
    "  %time tf.matmul(gpu_tensor, gpu_tensor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
